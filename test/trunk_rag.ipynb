{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0467fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (0.3.26)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.3.0-py3-none-any.whl.metadata (996 bytes)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: openai in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (1.95.1)\n",
      "Collecting openai\n",
      "  Downloading openai-1.97.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0.post1-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting unstructured\n",
      "  Downloading unstructured-0.18.9-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.3-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.3.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.1-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain) (0.3.68)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain) (0.4.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2->langchain) (2025.7.9)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers>=0.19.1 (from langchain-huggingface)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting huggingface-hub>=0.30.2 (from langchain-huggingface)\n",
      "  Downloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.14-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.6.3-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl.metadata (76 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting chardet (from unstructured)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Downloading lxml-6.0.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting nltk (from unstructured)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting beautifulsoup4 (from unstructured)\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 981.5/981.5 kB 7.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.13.0-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.39.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting wrapt (from unstructured)\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from unstructured) (5.9.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting torch>=1.11.0 (from sentence_transformers)\n",
      "  Using cached torch-2.7.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Using cached scikit_learn-1.7.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Downloading scipy-1.16.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting Pillow (from sentence_transformers)\n",
      "  Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.30.2->langchain-huggingface)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (78.1.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->unstructured)\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting webencodings (from html5lib->unstructured)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence_transformers)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting click (from nltk->unstructured)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib (from nltk->unstructured)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cryptography>=3.1 (from unstructured-client->unstructured)\n",
      "  Downloading cryptography-45.0.5-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
      "  Downloading pypdf-5.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting cffi>=1.14 (from cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
      "Downloading openai-1.97.0-py3-none-any.whl (764 kB)\n",
      "   ---------------------------------------- 0.0/765.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 765.0/765.0 kB 16.2 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 894.9/894.9 kB 20.4 MB/s eta 0:00:00\n",
      "Downloading langchain_huggingface-0.3.0-py3-none-any.whl (27 kB)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 24.1 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.12.14-cp312-cp312-win_amd64.whl (449 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.6.3-cp312-cp312-win_amd64.whl (45 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl (86 kB)\n",
      "Downloading faiss_cpu-1.11.0.post1-cp312-cp312-win_amd64.whl (14.9 MB)\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.6/14.9 MB 51.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.6/14.9 MB 51.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.7/14.9 MB 8.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.8/14.9 MB 6.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.8/14.9 MB 6.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.1/14.9 MB 6.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 9.7/14.9 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.3/14.9 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.8/14.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.4/14.9 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.9/14.9 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.9/14.9 MB 5.9 MB/s eta 0:00:00\n",
      "Downloading numpy-2.3.1-cp312-cp312-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/12.7 MB 7.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.7 MB 7.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.7/12.7 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 11.5/12.7 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 14.8 MB/s eta 0:00:00\n",
      "Downloading unstructured-0.18.9-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 47.3 MB/s eta 0:00:00\n",
      "Downloading pymupdf-1.26.3-cp39-abi3-win_amd64.whl (18.7 MB)\n",
      "   ---------------------------------------- 0.0/18.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 3.1/18.7 MB 61.4 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 3.1/18.7 MB 61.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 7.6/18.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 8.7/18.7 MB 11.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 11.3/18.7 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 13.6/18.7 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 15.5/18.7 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 17.3/18.7 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.7/18.7 MB 9.9 MB/s eta 0:00:00\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Downloading transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
      "   ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.8/10.8 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.2/10.8 MB 12.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.3/10.8 MB 15.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.9/10.8 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.8/10.8 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
      "Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 47.8 MB/s eta 0:00:00\n",
      "Using cached pandas-2.3.1-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl (43 kB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Downloading lxml-6.0.0-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.0/4.0 MB 48.1 MB/s eta 0:00:00\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached torch-2.7.1-cp312-cp312-win_amd64.whl (216.1 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 590.6/590.6 kB 21.9 MB/s eta 0:00:00\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 40.1 MB/s eta 0:00:00\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 43.7 MB/s eta 0:00:00\n",
      "Using cached scikit_learn-1.7.0-cp312-cp312-win_amd64.whl (10.7 MB)\n",
      "Downloading scipy-1.16.0-cp312-cp312-win_amd64.whl (38.4 MB)\n",
      "   ---------------------------------------- 0.0/38.4 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 9.4/38.4 MB 65.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 9.4/38.4 MB 65.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 11.5/38.4 MB 18.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 14.2/38.4 MB 19.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 14.4/38.4 MB 13.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 18.9/38.4 MB 15.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.0/38.4 MB 14.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.8/38.4 MB 13.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.6/38.4 MB 13.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.7/38.4 MB 12.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 28.8/38.4 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.7/38.4 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.0/38.4 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.3/38.4 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.2/38.4 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.4 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.4/38.4 MB 10.9 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading unstructured_client-0.39.1-py3-none-any.whl (212 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading cryptography-45.0.5-cp311-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.6/3.4 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.4/3.4 MB 8.4 MB/s eta 0:00:00\n",
      "Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Downloading pypdf-5.8.0-py3-none-any.whl (309 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993364 sha256=8b7d44a5a7002bd11f48a47ab072fc190e53602127a10d0ec4323d73c6ba3692\n",
      "  Stored in directory: c:\\users\\iwcyo\\appdata\\local\\pip\\cache\\wheels\\c1\\67\\88\\e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built langdetect\n",
      "Installing collected packages: webencodings, pytz, mpmath, filetype, wrapt, tzdata, threadpoolctl, sympy, soupsieve, safetensors, regex, rapidfuzz, python-magic, python-iso639, python-dotenv, pypdf, pymupdf, pycparser, propcache, Pillow, olefile, numpy, networkx, mypy-extensions, multidict, marshmallow, MarkupSafe, lxml, langdetect, joblib, httpx-sse, html5lib, fsspec, frozenlist, filelock, et-xmlfile, emoji, click, chardet, backoff, attrs, aiohappyeyeballs, aiofiles, yarl, typing-inspect, tiktoken, scipy, python-oxmsg, python-docx, pandas, openpyxl, nltk, jinja2, huggingface-hub, faiss-cpu, cffi, beautifulsoup4, aiosignal, torch, tokenizers, scikit-learn, pydantic-settings, openai, dataclasses-json, cryptography, aiohttp, unstructured-client, transformers, unstructured, sentence_transformers, langchain-openai, langchain-huggingface, langchain-community\n",
      "\n",
      "    ---------------------------------------  1/73 [pytz]\n",
      "   - --------------------------------------  2/73 [mpmath]\n",
      "   - --------------------------------------  2/73 [mpmath]\n",
      "   -- -------------------------------------  4/73 [wrapt]\n",
      "   -- -------------------------------------  5/73 [tzdata]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   ----- ---------------------------------- 10/73 [regex]\n",
      "   ------- -------------------------------- 14/73 [python-dotenv]\n",
      "   -------- ------------------------------- 15/73 [pypdf]\n",
      "   -------- ------------------------------- 16/73 [pymupdf]\n",
      "   -------- ------------------------------- 16/73 [pymupdf]\n",
      "   -------- ------------------------------- 16/73 [pymupdf]\n",
      "   --------- ------------------------------ 18/73 [propcache]\n",
      "   ---------- ----------------------------- 19/73 [Pillow]\n",
      "   ---------- ----------------------------- 19/73 [Pillow]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   -------------- ------------------------- 27/73 [lxml]\n",
      "   --------------- ------------------------ 29/73 [joblib]\n",
      "   --------------- ------------------------ 29/73 [joblib]\n",
      "   ----------------- ---------------------- 32/73 [fsspec]\n",
      "   ----------------- ---------------------- 32/73 [fsspec]\n",
      "   -------------------- ------------------- 38/73 [chardet]\n",
      "   -------------------- ------------------- 38/73 [chardet]\n",
      "   ------------------------ --------------- 45/73 [tiktoken]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   -------------------------- ------------- 48/73 [python-docx]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   --------------------------- ------------ 50/73 [openpyxl]\n",
      "   --------------------------- ------------ 50/73 [openpyxl]\n",
      "   --------------------------- ------------ 50/73 [openpyxl]\n",
      "   --------------------------- ------------ 51/73 [nltk]\n",
      "   --------------------------- ------------ 51/73 [nltk]\n",
      "   --------------------------- ------------ 51/73 [nltk]\n",
      "   --------------------------- ------------ 51/73 [nltk]\n",
      "   --------------------------- ------------ 51/73 [nltk]\n",
      "   --------------------------- ------------ 51/73 [nltk]\n",
      "   --------------------------- ------------ 51/73 [nltk]\n",
      "   ---------------------------- ----------- 52/73 [jinja2]\n",
      "   ----------------------------- ---------- 53/73 [huggingface-hub]\n",
      "   ----------------------------- ---------- 53/73 [huggingface-hub]\n",
      "   ----------------------------- ---------- 53/73 [huggingface-hub]\n",
      "   ----------------------------- ---------- 54/73 [faiss-cpu]\n",
      "   ----------------------------- ---------- 54/73 [faiss-cpu]\n",
      "   ------------------------------ --------- 56/73 [beautifulsoup4]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   -------------------------------- ------- 59/73 [tokenizers]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   --------------------------------- ------ 61/73 [pydantic-settings]\n",
      "  Attempting uninstall: openai\n",
      "   --------------------------------- ------ 61/73 [pydantic-settings]\n",
      "    Found existing installation: openai 1.95.1\n",
      "   --------------------------------- ------ 61/73 [pydantic-settings]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "    Uninstalling openai-1.95.1:\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "      Successfully uninstalled openai-1.95.1\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   ----------------------------------- ---- 64/73 [cryptography]\n",
      "   ----------------------------------- ---- 65/73 [aiohttp]\n",
      "   ----------------------------------- ---- 65/73 [aiohttp]\n",
      "   ------------------------------------ --- 66/73 [unstructured-client]\n",
      "   ------------------------------------ --- 66/73 [unstructured-client]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------- -- 68/73 [unstructured]\n",
      "   ------------------------------------- -- 68/73 [unstructured]\n",
      "   ------------------------------------- -- 68/73 [unstructured]\n",
      "   ------------------------------------- -- 68/73 [unstructured]\n",
      "   ------------------------------------- -- 69/73 [sentence_transformers]\n",
      "   ------------------------------------- -- 69/73 [sentence_transformers]\n",
      "   ------------------------------------- -- 69/73 [sentence_transformers]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------- 73/73 [langchain-community]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 Pillow-11.3.0 aiofiles-24.1.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 attrs-25.3.0 backoff-2.2.1 beautifulsoup4-4.13.4 cffi-1.17.1 chardet-5.2.0 click-8.2.1 cryptography-45.0.5 dataclasses-json-0.6.7 emoji-2.14.1 et-xmlfile-2.0.0 faiss-cpu-1.11.0.post1 filelock-3.18.0 filetype-1.2.0 frozenlist-1.7.0 fsspec-2025.7.0 html5lib-1.1 httpx-sse-0.4.1 huggingface-hub-0.33.4 jinja2-3.1.6 joblib-1.5.1 langchain-community-0.3.27 langchain-huggingface-0.3.0 langchain-openai-0.3.28 langdetect-1.0.9 lxml-6.0.0 marshmallow-3.26.1 mpmath-1.3.0 multidict-6.6.3 mypy-extensions-1.1.0 networkx-3.5 nltk-3.9.1 numpy-2.3.1 olefile-0.47 openai-1.97.0 openpyxl-3.1.5 pandas-2.3.1 propcache-0.3.2 pycparser-2.22 pydantic-settings-2.10.1 pymupdf-1.26.3 pypdf-5.8.0 python-docx-1.2.0 python-dotenv-1.1.1 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 pytz-2025.2 rapidfuzz-3.13.0 regex-2024.11.6 safetensors-0.5.3 scikit-learn-1.7.0 scipy-1.16.0 sentence_transformers-5.0.0 soupsieve-2.7 sympy-1.14.0 threadpoolctl-3.6.0 tiktoken-0.9.0 tokenizers-0.21.2 torch-2.7.1 transformers-4.53.2 typing-inspect-0.9.0 tzdata-2025.2 unstructured-0.18.9 unstructured-client-0.39.1 webencodings-0.5.1 wrapt-1.17.2 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'langdetect' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'langdetect'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain langchain-openai langchain-huggingface langchain-community openai \\\n",
    "    faiss-cpu  unstructured pymupdf python-docx \\\n",
    "    sentence_transformers numpy pandas networkx openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da1e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Using cached sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Using cached transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from sentence_transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence_transformers)\n",
      "  Using cached torch-2.7.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Using cached scikit_learn-1.7.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Using cached scipy-1.16.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence_transformers)\n",
      "  Using cached huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting Pillow (from sentence_transformers)\n",
      "  Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from sentence_transformers) (4.14.0)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.5)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (78.1.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence_transformers)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.6.15)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.5.1)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Using cached transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
      "Using cached huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
      "Using cached tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "Using cached fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached torch-2.7.1-cp312-cp312-win_amd64.whl (216.1 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading pillow-11.3.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 3.4/7.0 MB 14.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 15.9 MB/s eta 0:00:00\n",
      "Using cached scikit_learn-1.7.0-cp312-cp312-win_amd64.whl (10.7 MB)\n",
      "Using cached scipy-1.16.0-cp312-cp312-win_amd64.whl (38.4 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, scipy, safetensors, Pillow, MarkupSafe, fsspec, filelock, scikit-learn, jinja2, huggingface-hub, torch, tokenizers, transformers, sentence_transformers\n",
      "\n",
      "   ----------------------------------------  0/16 [mpmath]\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)'))': /packages/8c/ce/e7dfc873bdd9828f3b6e5c2bbb74e47a98ec23cc5c74fc4e54462f0d9204/pillow-11.3.0-cp312-cp312-win_amd64.whl\n",
      "ERROR: Could not install packages due to an OSError: [WinError 32] : 'c:\\\\Users\\\\iwcyou\\\\.conda\\\\envs\\\\dev\\\\Lib\\\\site-packages\\\\mpmath\\\\tests\\\\test_functions.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# conda install -c conda-forge faiss-gpu cudatoolkit=11.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d31c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iwcyo\\miniconda3\\envs\\dev\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\iwcyo\\miniconda3\\envs\\dev\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\iwcyo\\.cache\\huggingface\\hub\\models--BAAI--bge-small-zh. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "import torch\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-zh\",  # \n",
    "    model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}\n",
    ")\n",
    "\n",
    "# from langchain_openai import OpenAIEmbeddings #openai API Key\n",
    "#  HuggingFace \n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# embedding_model = SentenceTransformer(\"shibing624/text2vec-base-chinese\")\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    UnstructuredWordDocumentLoader,\n",
    "    UnstructuredExcelLoader,\n",
    ")\n",
    "import os\n",
    "\n",
    "# \n",
    "def load_documents_from_folder(folder_path: str):\n",
    "    docs = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif filename.endswith(\".docx\"):\n",
    "            loader = UnstructuredWordDocumentLoader(file_path)\n",
    "        elif filename.endswith(\".xlsx\") or filename.endswith(\".xls\"):\n",
    "            loader = UnstructuredExcelLoader(file_path)\n",
    "        else:\n",
    "            continue\n",
    "        docs.extend(loader.load())\n",
    "    return docs\n",
    "\n",
    "#  +  +  FAISS\n",
    "def build_faiss_index_from_folder(folder_path: str, index_save_path: str):\n",
    "    print(\" ...\")\n",
    "    raw_docs = load_documents_from_folder(folder_path)\n",
    "    \n",
    "    print(\" ...\")\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    split_docs = splitter.split_documents(raw_docs)\n",
    "    \n",
    "    print(\" ...\")\n",
    "    # embeddings = OpenAIEmbeddings()  #  HuggingFaceEmbeddings(model_name=\\\"...\\\")\n",
    "    embeddings = embedding_model  \n",
    "\n",
    "    print(\"  FAISS ...\")\n",
    "    vectordb = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "    print(f\" {index_save_path}\")\n",
    "    vectordb.save_local(index_save_path)\n",
    "    return vectordb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dbbf706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ...\n",
      " ...\n",
      " ...\n",
      "  FAISS ...\n",
      " ./faiss_law_index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x210f5ddf470>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "folder = \"./rule\"\n",
    "save_path = \"./faiss_law_index\"\n",
    "build_faiss_index_from_folder(folder, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a84644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "import torch\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "def query_law_index(query_text: str, index_path: str = \"./faiss_law_index\", k=3):\n",
    "    vectordb = FAISS.load_local(index_path, embedding_model, allow_dangerous_deserialization=True\n",
    ")\n",
    "    docs = vectordb.similarity_search(query_text, k=k)\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b67f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'filled_input': ''\n",
    "}\n",
    "rag_context = query_law_index(state['filled_input'])\n",
    "\n",
    "prompt = f\"\"\"\n",
    ":\n",
    "{rag_context}\n",
    "\n",
    ":\n",
    "{state['filled_input']}\n",
    "\n",
    "\n",
    "\n",
    "{{\n",
    "  \"responsibility\": \"\",\n",
    "  \"reason\": \"......\"\n",
    "}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "# sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2f154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-3015211d76cd4c7dace6a833c90f2424\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a43bd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "```json\n",
      "{\n",
      "  \"responsibility\": \"\",\n",
      "  \"reason\": \"\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI  #  deepseek-r1\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "#   FAISS \n",
    "vectordb = FAISS.load_local(\n",
    "    folder_path=\"./faiss_law_index\",  # \n",
    "    embeddings=HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-zh\"),\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "#  \n",
    "def query_law_index(query_text: str, k=3):\n",
    "    docs = vectordb.similarity_search(query_text, k=k)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "#   LangChain  DeepSeek\n",
    "# llm = ChatOpenAI(temperature=0, model=\"gpt-4\")  #  deepseek-r1 \n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"deepseek-chat\",  #  deepseek-chatdeepseek-coder \n",
    "    openai_api_base=\"https://api.deepseek.com/v1\",\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "#  \n",
    "state = {\n",
    "    'filled_input': ''\n",
    "}\n",
    "\n",
    "#  \n",
    "rag_context = query_law_index(state['filled_input'])\n",
    "\n",
    "#   Prompt\n",
    "prompt = f\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "{rag_context}\n",
    "\n",
    "\n",
    "{state['filled_input']}\n",
    "\n",
    "\n",
    " JSON \n",
    "{{\n",
    "  \"responsibility\": \"\",\n",
    "  \"reason\": \"......\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "#  \n",
    "response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "#  \n",
    "print(\" \")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039edad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " 17\n",
      "\n",
      "  3 \n",
      "\n",
      "---  1 ---\n",
      "\n",
      "\n",
      "\n",
      "---  2 ---\n",
      "   \\n \\n     \\n   /         \\n 1         A   /    1.\\n2.GPS\\n3.\\n4.\n",
      "\n",
      "---  3 ---\n",
      "  A   /    1.\\n2.GPS\\n3.\\n4. 1.\\n2.GPS70km/h40km/h\\n3.\\n4.81 \\n1.\\n2.\\n3.\\n4.\\n\\n1.\\n2.\\n3.\\n4. /    1.\\n2.\\n3.\n",
      "\n",
      " \n",
      "\n",
      ">>> Top-1 \n",
      "/   /  /   / , /   /  /   /  1\\n21\n",
      "\n",
      ">>> Top-2 \n",
      "  / \\n / / 1.\\n2. / \\n // //\n",
      "\n",
      ">>> Top-3 \n",
      "1.\\n\\n2.\\nGPS 1.\\n2. /    1.\\n\\n2.\\n\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "#  \n",
    "index_path = \"./faiss_law_index\"\n",
    "\n",
    "# \n",
    "vectordb = FAISS.load_local(\n",
    "    folder_path=index_path,\n",
    "    embeddings=HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-zh\"),\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "#  1. \n",
    "print(\" \")\n",
    "print(f\" {len(vectordb.docstore._dict)}\")\n",
    "\n",
    "#  2. \n",
    "print(\"\\n  3 \")\n",
    "for i, (doc_id, doc) in enumerate(vectordb.docstore._dict.items()):\n",
    "    print(f\"\\n---  {i+1} ---\")\n",
    "    print(doc.page_content)\n",
    "    if i >= 2:  # 3\n",
    "        break\n",
    "\n",
    "#  3. \n",
    "query = \"\"\n",
    "results = vectordb.similarity_search(query, k=3)\n",
    "\n",
    "print(\"\\n \")\n",
    "for i, r in enumerate(results):\n",
    "    print(f\"\\n>>> Top-{i+1} \")\n",
    "    print(r.page_content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
