{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0467fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (0.3.26)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.3.0-py3-none-any.whl.metadata (996 bytes)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: openai in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (1.95.1)\n",
      "Collecting openai\n",
      "  Downloading openai-1.97.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0.post1-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting unstructured\n",
      "  Downloading unstructured-0.18.9-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.3-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.3.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.1-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain) (0.3.68)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain) (0.4.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2->langchain) (2025.7.9)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers>=0.19.1 (from langchain-huggingface)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting huggingface-hub>=0.30.2 (from langchain-huggingface)\n",
      "  Downloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.14-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.6.3-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl.metadata (76 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting chardet (from unstructured)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Downloading lxml-6.0.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting nltk (from unstructured)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting beautifulsoup4 (from unstructured)\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 981.5/981.5 kB 7.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.13.0-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.39.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting wrapt (from unstructured)\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from unstructured) (5.9.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting torch>=1.11.0 (from sentence_transformers)\n",
      "  Using cached torch-2.7.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Using cached scikit_learn-1.7.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Downloading scipy-1.16.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting Pillow (from sentence_transformers)\n",
      "  Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.30.2->langchain-huggingface)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (78.1.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->unstructured)\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting webencodings (from html5lib->unstructured)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence_transformers)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting click (from nltk->unstructured)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib (from nltk->unstructured)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cryptography>=3.1 (from unstructured-client->unstructured)\n",
      "  Downloading cryptography-45.0.5-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
      "  Downloading pypdf-5.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting cffi>=1.14 (from cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
      "Downloading openai-1.97.0-py3-none-any.whl (764 kB)\n",
      "   ---------------------------------------- 0.0/765.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 765.0/765.0 kB 16.2 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 894.9/894.9 kB 20.4 MB/s eta 0:00:00\n",
      "Downloading langchain_huggingface-0.3.0-py3-none-any.whl (27 kB)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 24.1 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.12.14-cp312-cp312-win_amd64.whl (449 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.6.3-cp312-cp312-win_amd64.whl (45 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl (86 kB)\n",
      "Downloading faiss_cpu-1.11.0.post1-cp312-cp312-win_amd64.whl (14.9 MB)\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.6/14.9 MB 51.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.6/14.9 MB 51.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.7/14.9 MB 8.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.8/14.9 MB 6.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.8/14.9 MB 6.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.1/14.9 MB 6.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 9.7/14.9 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.3/14.9 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.8/14.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.4/14.9 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.9/14.9 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.9/14.9 MB 5.9 MB/s eta 0:00:00\n",
      "Downloading numpy-2.3.1-cp312-cp312-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/12.7 MB 7.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.7 MB 7.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.7/12.7 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 11.5/12.7 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 14.8 MB/s eta 0:00:00\n",
      "Downloading unstructured-0.18.9-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 47.3 MB/s eta 0:00:00\n",
      "Downloading pymupdf-1.26.3-cp39-abi3-win_amd64.whl (18.7 MB)\n",
      "   ---------------------------------------- 0.0/18.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 3.1/18.7 MB 61.4 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 3.1/18.7 MB 61.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 7.6/18.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 8.7/18.7 MB 11.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 11.3/18.7 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 13.6/18.7 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 15.5/18.7 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 17.3/18.7 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.7/18.7 MB 9.9 MB/s eta 0:00:00\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Downloading transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
      "   ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.8/10.8 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.2/10.8 MB 12.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.3/10.8 MB 15.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.9/10.8 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.8/10.8 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
      "Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 47.8 MB/s eta 0:00:00\n",
      "Using cached pandas-2.3.1-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl (43 kB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Downloading lxml-6.0.0-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.0/4.0 MB 48.1 MB/s eta 0:00:00\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached torch-2.7.1-cp312-cp312-win_amd64.whl (216.1 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 590.6/590.6 kB 21.9 MB/s eta 0:00:00\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 40.1 MB/s eta 0:00:00\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 43.7 MB/s eta 0:00:00\n",
      "Using cached scikit_learn-1.7.0-cp312-cp312-win_amd64.whl (10.7 MB)\n",
      "Downloading scipy-1.16.0-cp312-cp312-win_amd64.whl (38.4 MB)\n",
      "   ---------------------------------------- 0.0/38.4 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 9.4/38.4 MB 65.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 9.4/38.4 MB 65.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 11.5/38.4 MB 18.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 14.2/38.4 MB 19.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 14.4/38.4 MB 13.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 18.9/38.4 MB 15.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.0/38.4 MB 14.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.8/38.4 MB 13.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.6/38.4 MB 13.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.7/38.4 MB 12.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 28.8/38.4 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.7/38.4 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.0/38.4 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.3/38.4 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.2/38.4 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.4 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.4/38.4 MB 10.9 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading unstructured_client-0.39.1-py3-none-any.whl (212 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading cryptography-45.0.5-cp311-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.6/3.4 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.4/3.4 MB 8.4 MB/s eta 0:00:00\n",
      "Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Downloading pypdf-5.8.0-py3-none-any.whl (309 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993364 sha256=8b7d44a5a7002bd11f48a47ab072fc190e53602127a10d0ec4323d73c6ba3692\n",
      "  Stored in directory: c:\\users\\iwcyo\\appdata\\local\\pip\\cache\\wheels\\c1\\67\\88\\e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built langdetect\n",
      "Installing collected packages: webencodings, pytz, mpmath, filetype, wrapt, tzdata, threadpoolctl, sympy, soupsieve, safetensors, regex, rapidfuzz, python-magic, python-iso639, python-dotenv, pypdf, pymupdf, pycparser, propcache, Pillow, olefile, numpy, networkx, mypy-extensions, multidict, marshmallow, MarkupSafe, lxml, langdetect, joblib, httpx-sse, html5lib, fsspec, frozenlist, filelock, et-xmlfile, emoji, click, chardet, backoff, attrs, aiohappyeyeballs, aiofiles, yarl, typing-inspect, tiktoken, scipy, python-oxmsg, python-docx, pandas, openpyxl, nltk, jinja2, huggingface-hub, faiss-cpu, cffi, beautifulsoup4, aiosignal, torch, tokenizers, scikit-learn, pydantic-settings, openai, dataclasses-json, cryptography, aiohttp, unstructured-client, transformers, unstructured, sentence_transformers, langchain-openai, langchain-huggingface, langchain-community\n",
      "\n",
      "    ---------------------------------------  1/73 [pytz]\n",
      "   - --------------------------------------  2/73 [mpmath]\n",
      "   - --------------------------------------  2/73 [mpmath]\n",
      "   -- -------------------------------------  4/73 [wrapt]\n",
      "   -- -------------------------------------  5/73 [tzdata]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   --- ------------------------------------  7/73 [sympy]\n",
      "   ----- ---------------------------------- 10/73 [regex]\n",
      "   ------- -------------------------------- 14/73 [python-dotenv]\n",
      "   -------- ------------------------------- 15/73 [pypdf]\n",
      "   -------- ------------------------------- 16/73 [pymupdf]\n",
      "   -------- ------------------------------- 16/73 [pymupdf]\n",
      "   -------- ------------------------------- 16/73 [pymupdf]\n",
      "   --------- ------------------------------ 18/73 [propcache]\n",
      "   ---------- ----------------------------- 19/73 [Pillow]\n",
      "   ---------- ----------------------------- 19/73 [Pillow]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ----------- ---------------------------- 21/73 [numpy]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   ------------ --------------------------- 22/73 [networkx]\n",
      "   -------------- ------------------------- 27/73 [lxml]\n",
      "   --------------- ------------------------ 29/73 [joblib]\n",
      "   --------------- ------------------------ 29/73 [joblib]\n",
      "   ----------------- ---------------------- 32/73 [fsspec]\n",
      "   ----------------- ---------------------- 32/73 [fsspec]\n",
      "   -------------------- ------------------- 38/73 [chardet]\n",
      "   -------------------- ------------------- 38/73 [chardet]\n",
      "   ------------------------ --------------- 45/73 [tiktoken]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   ------------------------- -------------- 46/73 [scipy]\n",
      "   -------------------------- ------------- 48/73 [python-docx]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   -------------------------- ------------- 49/73 [pandas]\n",
      "   --------------------------- ------------ 50/73 [openpyxl]\n",
      "   --------------------------- ------------ 50/73 [openpyxl]\n",
      "   --------------------------- ------------ 50/73 [openpyxl]\n",
      "   --------------------------- ------------ 51/73 [nltk]\n",
      "   --------------------------- ------------ 51/73 [nltk]\n",
      "   --------------------------- ------------ 51/73 [nltk]\n",
      "   --------------------------- ------------ 51/73 [nltk]\n",
      "   --------------------------- ------------ 51/73 [nltk]\n",
      "   --------------------------- ------------ 51/73 [nltk]\n",
      "   --------------------------- ------------ 51/73 [nltk]\n",
      "   ---------------------------- ----------- 52/73 [jinja2]\n",
      "   ----------------------------- ---------- 53/73 [huggingface-hub]\n",
      "   ----------------------------- ---------- 53/73 [huggingface-hub]\n",
      "   ----------------------------- ---------- 53/73 [huggingface-hub]\n",
      "   ----------------------------- ---------- 54/73 [faiss-cpu]\n",
      "   ----------------------------- ---------- 54/73 [faiss-cpu]\n",
      "   ------------------------------ --------- 56/73 [beautifulsoup4]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   ------------------------------- -------- 58/73 [torch]\n",
      "   -------------------------------- ------- 59/73 [tokenizers]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   -------------------------------- ------- 60/73 [scikit-learn]\n",
      "   --------------------------------- ------ 61/73 [pydantic-settings]\n",
      "  Attempting uninstall: openai\n",
      "   --------------------------------- ------ 61/73 [pydantic-settings]\n",
      "    Found existing installation: openai 1.95.1\n",
      "   --------------------------------- ------ 61/73 [pydantic-settings]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "    Uninstalling openai-1.95.1:\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "      Successfully uninstalled openai-1.95.1\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   --------------------------------- ------ 62/73 [openai]\n",
      "   ----------------------------------- ---- 64/73 [cryptography]\n",
      "   ----------------------------------- ---- 65/73 [aiohttp]\n",
      "   ----------------------------------- ---- 65/73 [aiohttp]\n",
      "   ------------------------------------ --- 66/73 [unstructured-client]\n",
      "   ------------------------------------ --- 66/73 [unstructured-client]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------ --- 67/73 [transformers]\n",
      "   ------------------------------------- -- 68/73 [unstructured]\n",
      "   ------------------------------------- -- 68/73 [unstructured]\n",
      "   ------------------------------------- -- 68/73 [unstructured]\n",
      "   ------------------------------------- -- 68/73 [unstructured]\n",
      "   ------------------------------------- -- 69/73 [sentence_transformers]\n",
      "   ------------------------------------- -- 69/73 [sentence_transformers]\n",
      "   ------------------------------------- -- 69/73 [sentence_transformers]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------  72/73 [langchain-community]\n",
      "   ---------------------------------------- 73/73 [langchain-community]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 Pillow-11.3.0 aiofiles-24.1.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 attrs-25.3.0 backoff-2.2.1 beautifulsoup4-4.13.4 cffi-1.17.1 chardet-5.2.0 click-8.2.1 cryptography-45.0.5 dataclasses-json-0.6.7 emoji-2.14.1 et-xmlfile-2.0.0 faiss-cpu-1.11.0.post1 filelock-3.18.0 filetype-1.2.0 frozenlist-1.7.0 fsspec-2025.7.0 html5lib-1.1 httpx-sse-0.4.1 huggingface-hub-0.33.4 jinja2-3.1.6 joblib-1.5.1 langchain-community-0.3.27 langchain-huggingface-0.3.0 langchain-openai-0.3.28 langdetect-1.0.9 lxml-6.0.0 marshmallow-3.26.1 mpmath-1.3.0 multidict-6.6.3 mypy-extensions-1.1.0 networkx-3.5 nltk-3.9.1 numpy-2.3.1 olefile-0.47 openai-1.97.0 openpyxl-3.1.5 pandas-2.3.1 propcache-0.3.2 pycparser-2.22 pydantic-settings-2.10.1 pymupdf-1.26.3 pypdf-5.8.0 python-docx-1.2.0 python-dotenv-1.1.1 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 pytz-2025.2 rapidfuzz-3.13.0 regex-2024.11.6 safetensors-0.5.3 scikit-learn-1.7.0 scipy-1.16.0 sentence_transformers-5.0.0 soupsieve-2.7 sympy-1.14.0 threadpoolctl-3.6.0 tiktoken-0.9.0 tokenizers-0.21.2 torch-2.7.1 transformers-4.53.2 typing-inspect-0.9.0 tzdata-2025.2 unstructured-0.18.9 unstructured-client-0.39.1 webencodings-0.5.1 wrapt-1.17.2 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'langdetect' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'langdetect'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain langchain-openai langchain-huggingface langchain-community openai \\\n",
    "    faiss-cpu  unstructured pymupdf python-docx \\\n",
    "    sentence_transformers numpy pandas networkx openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da1e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Using cached sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Using cached transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from sentence_transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence_transformers)\n",
      "  Using cached torch-2.7.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Using cached scikit_learn-1.7.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Using cached scipy-1.16.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence_transformers)\n",
      "  Using cached huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting Pillow (from sentence_transformers)\n",
      "  Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from sentence_transformers) (4.14.0)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.5)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (78.1.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence_transformers)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.6.15)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.5.1)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Using cached transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
      "Using cached huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
      "Using cached tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "Using cached fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached torch-2.7.1-cp312-cp312-win_amd64.whl (216.1 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading pillow-11.3.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 3.4/7.0 MB 14.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 15.9 MB/s eta 0:00:00\n",
      "Using cached scikit_learn-1.7.0-cp312-cp312-win_amd64.whl (10.7 MB)\n",
      "Using cached scipy-1.16.0-cp312-cp312-win_amd64.whl (38.4 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, scipy, safetensors, Pillow, MarkupSafe, fsspec, filelock, scikit-learn, jinja2, huggingface-hub, torch, tokenizers, transformers, sentence_transformers\n",
      "\n",
      "   ----------------------------------------  0/16 [mpmath]\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)'))': /packages/8c/ce/e7dfc873bdd9828f3b6e5c2bbb74e47a98ec23cc5c74fc4e54462f0d9204/pillow-11.3.0-cp312-cp312-win_amd64.whl\n",
      "ERROR: Could not install packages due to an OSError: [WinError 32] 另一个程序正在使用此文件，进程无法访问。: 'c:\\\\Users\\\\iwcyou\\\\.conda\\\\envs\\\\dev\\\\Lib\\\\site-packages\\\\mpmath\\\\tests\\\\test_functions.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# conda install -c conda-forge faiss-gpu cudatoolkit=11.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d31c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iwcyo\\miniconda3\\envs\\dev\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\iwcyo\\miniconda3\\envs\\dev\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\iwcyo\\.cache\\huggingface\\hub\\models--BAAI--bge-small-zh. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "import torch\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-zh\",  # 或其他\n",
    "    model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}\n",
    ")\n",
    "\n",
    "# from langchain_openai import OpenAIEmbeddings #需要openai的 API Key\n",
    "# 如果需要使用 HuggingFace 的模型\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# embedding_model = SentenceTransformer(\"shibing624/text2vec-base-chinese\")\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    UnstructuredWordDocumentLoader,\n",
    "    UnstructuredExcelLoader,\n",
    ")\n",
    "import os\n",
    "\n",
    "# 支持加载多种格式的文档\n",
    "def load_documents_from_folder(folder_path: str):\n",
    "    docs = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif filename.endswith(\".docx\"):\n",
    "            loader = UnstructuredWordDocumentLoader(file_path)\n",
    "        elif filename.endswith(\".xlsx\") or filename.endswith(\".xls\"):\n",
    "            loader = UnstructuredExcelLoader(file_path)\n",
    "        else:\n",
    "            continue\n",
    "        docs.extend(loader.load())\n",
    "    return docs\n",
    "\n",
    "# 切块 + 嵌入 + 存入 FAISS\n",
    "def build_faiss_index_from_folder(folder_path: str, index_save_path: str):\n",
    "    print(\" 加载法规文档中...\")\n",
    "    raw_docs = load_documents_from_folder(folder_path)\n",
    "    \n",
    "    print(\" 切分文档为片段...\")\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    split_docs = splitter.split_documents(raw_docs)\n",
    "    \n",
    "    print(\" 构建嵌入向量...\")\n",
    "    # embeddings = OpenAIEmbeddings()  # 或 HuggingFaceEmbeddings(model_name=\\\"...\\\")\n",
    "    embeddings = embedding_model  \n",
    "\n",
    "    print(\" 构建 FAISS 向量数据库...\")\n",
    "    vectordb = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "    print(f\" 保存向量数据库至：{index_save_path}\")\n",
    "    vectordb.save_local(index_save_path)\n",
    "    return vectordb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dbbf706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 加载法规文档中...\n",
      " 切分文档为片段...\n",
      " 构建嵌入向量...\n",
      " 构建 FAISS 向量数据库...\n",
      " 保存向量数据库至：./faiss_law_index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x210f5ddf470>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 示例调用\n",
    "folder = \"./rule\"\n",
    "save_path = \"./faiss_law_index\"\n",
    "build_faiss_index_from_folder(folder, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a84644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "import torch\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "def query_law_index(query_text: str, index_path: str = \"./faiss_law_index\", k=3):\n",
    "    vectordb = FAISS.load_local(index_path, embedding_model, allow_dangerous_deserialization=True\n",
    ")\n",
    "    docs = vectordb.similarity_search(query_text, k=k)\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b67f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'filled_input': '运输企业在运输过程中，存在泥头车路面遗洒，责任如何划分？'\n",
    "}\n",
    "rag_context = query_law_index(state['filled_input'])\n",
    "\n",
    "prompt = f\"\"\"\n",
    "请参考以下法规内容作为决策依据:\n",
    "{rag_context}\n",
    "\n",
    "描述如下:\n",
    "{state['filled_input']}\n",
    "\n",
    "请判断责任归属及依据。\n",
    "输出：\n",
    "{{\n",
    "  \"responsibility\": \"运输企业\",\n",
    "  \"reason\": \"......\"\n",
    "}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "# sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2f154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-3015211d76cd4c7dace6a833c90f2424\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a43bd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 模型返回：\n",
      "```json\n",
      "{\n",
      "  \"responsibility\": \"运输企业\",\n",
      "  \"reason\": \"根据法规内容，运输企业作为整改主体，应确保泥头车在运输过程中遵守车辆操作规范和运输流程合规性。具体包括驾驶新型智能全密闭式泥头车，装载量不得超过核定标准，杜绝超载；每日出车前、收车后对车辆进行基本维护检查，并保持车内外整洁；按规定时间和路线行驶，进出工地前配合监管员完成车身冲洗，确保无带泥上路现象。运输企业在运输过程中存在泥头车路面遗洒，表明其未履行上述责任，因此责任归属于运输企业。\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI  # 可替换为 deepseek-r1\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "#  加载 FAISS 向量库\n",
    "vectordb = FAISS.load_local(\n",
    "    folder_path=\"./faiss_law_index\",  # 你保存的知识库路径\n",
    "    embeddings=HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-zh\"),\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "#  构造检索函数\n",
    "def query_law_index(query_text: str, k=3):\n",
    "    docs = vectordb.similarity_search(query_text, k=k)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "#  构造 LangChain 模型（可替换为 DeepSeek）\n",
    "# llm = ChatOpenAI(temperature=0, model=\"gpt-4\")  # 或调用 deepseek-r1 的兼容封装\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"deepseek-chat\",  # 可以使用 deepseek-chat、deepseek-coder 等\n",
    "    openai_api_base=\"https://api.deepseek.com/v1\",\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "#  模拟状态输入\n",
    "state = {\n",
    "    'filled_input': '运输企业在运输过程中，存在泥头车路面遗洒，责任如何划分？'\n",
    "}\n",
    "\n",
    "#  查询法规知识库\n",
    "rag_context = query_law_index(state['filled_input'])\n",
    "\n",
    "#  构造最终 Prompt\n",
    "prompt = f\"\"\"\n",
    "你是一位城市治理法规专家，请结合以下法规内容判断城市泥头车污染事件的责任归属。\n",
    "\n",
    "法规内容如下：\n",
    "{rag_context}\n",
    "\n",
    "描述如下：\n",
    "{state['filled_input']}\n",
    "\n",
    "请判断责任归属，并说明理由。\n",
    "输出 JSON 格式：\n",
    "{{\n",
    "  \"responsibility\": \"运输企业\",\n",
    "  \"reason\": \"......\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "#  调用大模型进行回答\n",
    "response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "#  输出结果\n",
    "print(\"📘 模型返回：\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039edad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 向量库加载成功！\n",
      "📄 当前文档片段数：17\n",
      "\n",
      "🔍 文档片段预览（前 3 条）：\n",
      "\n",
      "--- 文档 1 ---\n",
      "事件分类分级清单\n",
      "（试行第一版）\n",
      "\n",
      "--- 文档 2 ---\n",
      "序号 一级分类 二级分类 三级分类\\n事件描述 四级分类\\n事件描述 要素 行业标准（法律（文件）依据） 区域（红线内、红线外、全域） 满足事项上报的时段 事件\\n等级 圈层提级 环节 时限（小时/天） 主体 主体名称 岗位 人 职责 业务标准 考核标准 考核周期 备注\\n（非必填） 1 城市管理 道路保洁 道路遗撒 泥头车遗撒 消防通道 《深圳经济特区市容和环境卫生管理条例》、《深圳市建筑废弃物管理办法》 全域 全天 A 自治 发现 / 自查主体 运输企业 监管员 1.落实车辆与驾驶员的资质管理\\n2.动态监管（GPS）实时追踪泥头车\\n3.安装安全装置（如全封闭式货箱）\\n4.定期组织驾驶员安全培训\n",
      "\n",
      "--- 文档 3 ---\n",
      "全域 全天 A 自治 发现 / 自查主体 运输企业 监管员 1.落实车辆与驾驶员的资质管理\\n2.动态监管（GPS）实时追踪泥头车\\n3.安装安全装置（如全封闭式货箱）\\n4.定期组织驾驶员安全培训 1.证件审核：驾驶员需持有与准驾车型匹配的驾驶证、特种作业证，并完成泥头车专项安全培训。车辆须具备行驶证、道路运输经营许可证、城市建筑垃圾准运证。\\n2.动态监管：所有车辆强制安装带卫星定位功能的GPS设备，并接入统一监控平台。设置限速（高速公路70km/h、城市道路40km/h）、限定行驶路线及时间，实时预警超速、偏离路线等行为。\\n3.封闭要求：货箱须采用全封闭平推式顶盖，尾门密封防漏撒，严禁超高超载。\\n4.培训频率：新驾驶员岗前培训≥8小时，在职驾驶员每季度至少1次安全培训。 （一）正面清单：\\n1.合法运营\\n2.车辆安全规范\\n3.车辆安全运输\\n4.建立信息化管理\\n（二）负面清单：\\n1.无证运营\\n2.车辆安全隐患\\n3.车辆违规运输\\n4.缺失信息化管理 / 自查主体 工地企业 监管员 1.选择合规运输企业\\n2.施工现场管理\\n3.周边环境保护\n",
      "\n",
      "🔎 示例检索结果：\n",
      "\n",
      ">>> Top-1 相关法规内容：\n",
      "/ 监管主体 公安交警 / 强化路面运输管理，充分利用“雪亮工程”、道路查违摄像头、车牌号自动识别、不停车超限检测等技术手段，及时发现、查出建筑废弃物运输过程中存在的违法行为。对于发现的运输车辆存在超载、车体不洁、沿途撒漏等违规、违法行为，要查清弃土路线，并及时向区城管局、各街道办等成员单位通报信息，做到全链条监管。 / 监管主体 区交通局 / 履行执法监督检查职能，及时备案、汇总并分享泥头车备案及所属企业信息。加强建筑废弃物运输车辆道路执法检查,对未履行安全生产主体责任的企业严格按照相关法律法规依法处罚。 / 监管主体 区水务局 / 查处向排水检查井、雨水口和排水明渠内排放或者倾倒污泥、淤泥等废弃物的行为 / 监管主体 区城管局 / 负责指导、监督街道执法队开展泥头车遗撒等执法工作，对街道执法成效进行考核，落实规范化建设，推进执法业务提质提效。 （1）负责梳理相关法律法规，结合执法实务，明确泥头车执法工作指引。\\n（2）推行环卫、绿化、市容巡查三者实行职责绑定、一岗多责制，市容巡查员强化泥头车遗撒问题发现职能。三是针对泥头车执法相关问题对街道执法队开展业务培训1次及以上。\n",
      "\n",
      ">>> Top-2 相关法规内容：\n",
      "路面硬底化情况、车身整洁度、车辆形式规范性、冲水设施设置情况、围栏作业情况、视频资料管理情况。 监督 / 管理主体\\n（监督泥头车运输方面） 交通局/物业城市服务供应商 货物运输管理岗/城市管家 1.交通局货物运输管理岗：制定泥头车运输管理政策，核发道路运输经营许可证。监督运输企业资质，要求泥头车必须采取密闭措施，防止物料遗撒。\\n2.城市管家：在日常主车道巡查中监督是否存在泥头车头车道路遗撒、车身挂泥、超高装载等问题，在事件发生后，需及时制止、教育批评、组织清理（如需）并协助执法部门取证。 / 管理主体\\n（监督施工管理方面） 住建局/街道办事处/社区 工程监管岗/巡查员/网格员\n",
      "\n",
      ">>> Top-3 相关法规内容：\n",
      "1.车辆操作规范\\n驾驶新型智能全密闭式泥头车，装载量不得超过核定标准，杜绝超载。每日出车前、收车后对车辆进行基本维护检查（如刹车系统、灯光、密封装置），并保持车内外整洁。\\n2.运输流程合规性\\n按规定时间和路线行驶，进出工地前配合监管员完成车身冲洗，确保无带泥上路现象。使用车载智能设备（如盲区报警系统、GPS定位），实时上传行驶数据至监管平台。 1.车辆操作规范考核\\n2.运输流程规范考核 / 整改主体 工地企业 工地工人 1.工地出入口清洁维护\\n负责操作高压冲洗设备，确保每辆泥头车离场前彻底清洁车身、车轮，防止带泥上路。及时清理工地出入口及周边道路的洒漏泥土、积水，保持路面整洁。\\n2.施工过程污染防控\\n在装卸渣土时协助检查车辆密封性，发现装载过满或密封装置故障需立即上报。配合监管员巡查工地内运输路线，及时修复破损路面或围挡，减少扬尘和泥土外溢风险。\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "#  设置向量库路径\n",
    "index_path = \"./faiss_law_index\"\n",
    "\n",
    "# 加载向量库（本地，确保路径正确）\n",
    "vectordb = FAISS.load_local(\n",
    "    folder_path=index_path,\n",
    "    embeddings=HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-zh\"),\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "#  1. 打印数据库信息\n",
    "print(\"📦 向量库加载成功！\")\n",
    "print(f\"📄 当前文档片段数：{len(vectordb.docstore._dict)}\")\n",
    "\n",
    "#  2. 显示前几条内容\n",
    "print(\"\\n🔍 文档片段预览（前 3 条）：\")\n",
    "for i, (doc_id, doc) in enumerate(vectordb.docstore._dict.items()):\n",
    "    print(f\"\\n--- 文档 {i+1} ---\")\n",
    "    print(doc.page_content)\n",
    "    if i >= 2:  # 只展示前3条\n",
    "        break\n",
    "\n",
    "#  3. 可选：执行一次关键字检索\n",
    "query = \"泥头车运输过程中未密闭造成路面污染，如何认定责任？\"\n",
    "results = vectordb.similarity_search(query, k=3)\n",
    "\n",
    "print(\"\\n🔎 示例检索结果：\")\n",
    "for i, r in enumerate(results):\n",
    "    print(f\"\\n>>> Top-{i+1} 相关法规内容：\")\n",
    "    print(r.page_content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
