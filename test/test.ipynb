{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f57ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (1.97.0)\n",
      "Collecting openai\n",
      "  Using cached openai-1.97.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: langgraph in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (0.5.4)\n",
      "Requirement already satisfied: dotenv in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: langchain in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (0.3.26)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-huggingface\n",
      "  Using cached langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting unstructured\n",
      "  Using cached unstructured-0.18.11-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pymupdf\n",
      "  Using cached pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting python-docx\n",
      "  Using cached python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (1.26.4)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: networkx in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (3.5)\n",
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: langchain-core>=0.1 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langgraph) (0.3.70)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langgraph) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langgraph) (0.5.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langgraph) (0.1.74)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.11.0)\n",
      "Requirement already satisfied: python-dotenv in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from dotenv) (1.1.1)\n",
      "Collecting langchain-core>=0.1 (from langgraph)\n",
      "  Using cached langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Using cached tiktoken-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers>=0.19.1 (from langchain-huggingface)\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting huggingface-hub>=0.33.4 (from langchain-huggingface)\n",
      "  Using cached huggingface_hub-0.34.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Using cached aiohttp-3.12.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached multidict-6.6.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Using cached lxml-6.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting nltk (from unstructured)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting beautifulsoup4 (from unstructured)\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting emoji (from unstructured)\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Using cached python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting rapidfuzz (from unstructured)\n",
      "  Using cached rapidfuzz-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Using cached unstructured_client-0.41.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting wrapt (from unstructured)\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: psutil in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from unstructured) (5.9.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Using cached python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Using cached transformers-4.54.0-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from sentence_transformers) (2.7.1)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Using cached scikit_learn-1.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Using cached scipy-1.16.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: Pillow in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from sentence_transformers) (11.3.0)\n",
      "Requirement already satisfied: filelock in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (3.18.0)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.7.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.33.4->langchain-huggingface)\n",
      "  Using cached hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->unstructured)\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting webencodings (from html5lib->unstructured)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Collecting click (from nltk->unstructured)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib (from nltk->unstructured)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Using cached olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cryptography>=3.1 (from unstructured-client->unstructured)\n",
      "  Using cached cryptography-45.0.5-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /home/fk/miniconda3/envs/holistic/lib/python3.12/site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
      "  Using cached pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting cffi>=1.14 (from cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Using cached openai-1.97.1-py3-none-any.whl (764 kB)\n",
      "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_core-0.3.72-py3-none-any.whl (442 kB)\n",
      "Using cached langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Using cached langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
      "Using cached tiktoken-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
      "Using cached langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "Using cached aiohttp-3.12.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.6.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
      "Using cached unstructured-0.18.11-py3-none-any.whl (1.8 MB)\n",
      "Using cached pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
      "Using cached python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Using cached sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Using cached transformers-4.54.0-py3-none-any.whl (11.2 MB)\n",
      "Using cached huggingface_hub-0.34.1-py3-none-any.whl (558 kB)\n",
      "Using cached hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "Using cached pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Using cached lxml-6.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading scipy-1.16.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading unstructured_client-0.41.0-py3-none-any.whl (211 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading cryptography-45.0.5-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479 kB)\n",
      "Downloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "\u001b[33m  DEPRECATION: Building 'langdetect' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'langdetect'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993332 sha256=e5f67df070dda8e9cc9d36d18ea8ede4ea7f1fb2f03a0db29b112e475aadf611\n",
      "  Stored in directory: /home/fk/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built langdetect\n",
      "Installing collected packages: webencodings, pytz, filetype, wrapt, tzdata, threadpoolctl, soupsieve, safetensors, regex, rapidfuzz, python-magic, python-iso639, pypdf, pymupdf, pycparser, propcache, olefile, numpy, mypy-extensions, multidict, marshmallow, lxml, langdetect, joblib, httpx-sse, html5lib, hf-xet, frozenlist, et-xmlfile, emoji, click, backoff, attrs, aiohappyeyeballs, aiofiles, yarl, typing-inspect, tiktoken, scipy, python-oxmsg, python-docx, pandas, openpyxl, nltk, huggingface-hub, cffi, beautifulsoup4, aiosignal, tokenizers, scikit-learn, pydantic-settings, openai, dataclasses-json, cryptography, aiohttp, unstructured-client, transformers, langchain-core, unstructured, sentence_transformers, langchain-text-splitters, langchain-openai, langchain-huggingface, langchain, langchain-community\n",
      "\u001b[2K  Attempting uninstall: numpym\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/65\u001b[0m [pymupdf]\n",
      "\u001b[2K    Found existing installation: numpy 1.26.4━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/65\u001b[0m [pymupdf]\n",
      "\u001b[2K    Uninstalling numpy-1.26.4:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/65\u001b[0m [pymupdf]\n",
      "\u001b[2K      Successfully uninstalled numpy-1.26.4━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/65\u001b[0m [pymupdf]\n",
      "\u001b[2K  Attempting uninstall: openai━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m50/65\u001b[0m [pydantic-settings]\n",
      "\u001b[2K    Found existing installation: openai 1.97.00m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m50/65\u001b[0m [pydantic-settings]\n",
      "\u001b[2K    Uninstalling openai-1.97.0:━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m50/65\u001b[0m [pydantic-settings]\n",
      "\u001b[2K      Successfully uninstalled openai-1.97.0\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m50/65\u001b[0m [pydantic-settings]\n",
      "\u001b[2K  Attempting uninstall: langchain-core━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m56/65\u001b[0m [transformers]client]\n",
      "\u001b[2K    Found existing installation: langchain-core 0.3.7090m━━━━━\u001b[0m \u001b[32m56/65\u001b[0m [transformers]\n",
      "\u001b[2K    Uninstalling langchain-core-0.3.70:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m56/65\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled langchain-core-0.3.70╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m57/65\u001b[0m [langchain-core]\n",
      "\u001b[2K  Attempting uninstall: langchain-text-splitters\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m59/65\u001b[0m [sentence_transformers]\n",
      "\u001b[2K    Found existing installation: langchain-text-splitters 0.3.8[0m \u001b[32m59/65\u001b[0m [sentence_transformers]\n",
      "\u001b[2K    Uninstalling langchain-text-splitters-0.3.8:m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m59/65\u001b[0m [sentence_transformers]\n",
      "\u001b[2K      Successfully uninstalled langchain-text-splitters-0.3.8━\u001b[0m \u001b[32m59/65\u001b[0m [sentence_transformers]\n",
      "\u001b[2K  Attempting uninstall: langchain━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m59/65\u001b[0m [sentence_transformers]\n",
      "\u001b[2K    Found existing installation: langchain 0.3.26╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m59/65\u001b[0m [sentence_transformers]\n",
      "\u001b[2K    Uninstalling langchain-0.3.26:━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m59/65\u001b[0m [sentence_transformers]\n",
      "\u001b[2K      Successfully uninstalled langchain-0.3.26[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m63/65\u001b[0m [langchain]formers]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65/65\u001b[0m [langchain-community]ommunity]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiofiles-24.1.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 attrs-25.3.0 backoff-2.2.1 beautifulsoup4-4.13.4 cffi-1.17.1 click-8.2.1 cryptography-45.0.5 dataclasses-json-0.6.7 emoji-2.14.1 et-xmlfile-2.0.0 filetype-1.2.0 frozenlist-1.7.0 hf-xet-1.1.5 html5lib-1.1 httpx-sse-0.4.1 huggingface-hub-0.34.1 joblib-1.5.1 langchain-0.3.27 langchain-community-0.3.27 langchain-core-0.3.72 langchain-huggingface-0.3.1 langchain-openai-0.3.28 langchain-text-splitters-0.3.9 langdetect-1.0.9 lxml-6.0.0 marshmallow-3.26.1 multidict-6.6.3 mypy-extensions-1.1.0 nltk-3.9.1 numpy-2.3.2 olefile-0.47 openai-1.97.1 openpyxl-3.1.5 pandas-2.3.1 propcache-0.3.2 pycparser-2.22 pydantic-settings-2.10.1 pymupdf-1.26.3 pypdf-5.9.0 python-docx-1.2.0 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 pytz-2025.2 rapidfuzz-3.13.0 regex-2024.11.6 safetensors-0.5.3 scikit-learn-1.7.1 scipy-1.16.1 sentence_transformers-5.0.0 soupsieve-2.7 threadpoolctl-3.6.0 tiktoken-0.9.0 tokenizers-0.21.2 transformers-4.54.0 typing-inspect-0.9.0 tzdata-2025.2 unstructured-0.18.11 unstructured-client-0.41.0 webencodings-0.5.1 wrapt-1.17.2 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Libraries to install\n",
    "%pip install -U openai langgraph dotenv \\\n",
    "    langchain langchain-openai langchain-huggingface langchain-community \\\n",
    "    unstructured pymupdf python-docx \\\n",
    "    sentence_transformers numpy pandas networkx openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c0a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "# sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a282e948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Okay, the user just said \"Hello\". I should respond in a friendly and welcoming manner. Maybe ask how I can assist them today. Keep it open-ended so they feel comfortable to ask anything. Let me make sure the response is warm and approachable.\n",
      "\n",
      "Hmm, should I use an exclamation mark to sound more enthusiastic? Yeah, \"Hello! How can I assist you today?\" sounds good. It's simple and to the point. I don't want to overwhelm them with too much text. Just let them know I'm here to help. Yep, that works.\n",
      "</think>\n",
      "\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# DeepSeek-r1 model\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ['W8A8_API_KEY'], base_url=os.environ['BASE_URL'])\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"r1w8a8\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=\"anthropic:claude-3-7-sonnet-latest\",\n",
    "    tools=[get_weather],\n",
    "    prompt=\"You are a helpful assistant\"\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#在工单接收节点添加了信息不足反馈机制，但并不包括复杂逻辑以及RAG\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Optional\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.chat_models import ChatOpenAI  # 可替换为DeepSeek-R1\n",
    "import json\n",
    "\n",
    "# ----------- 状态定义 -----------\n",
    "class State(TypedDict):\n",
    "    user_input: str\n",
    "    missing_fields: Optional[list]\n",
    "    json_output: Optional[dict]\n",
    "\n",
    "# ----------- 初始化模型 -----------\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)  # 替换为 DeepSeek-R1 接口也可\n",
    "\n",
    "# ----------- 节点定义 -----------\n",
    "\n",
    "# 1. 检查输入完整性\n",
    "def check_completeness(state: State) -> State:\n",
    "    prompt = f\"\"\"\n",
    "你是一位城市治理智能助理，现在收到一条来自环卫工人的描述，请你判断该描述是否包含以下三类信息：\n",
    "1. 时间信息\n",
    "2. 地点信息\n",
    "3. 遗洒情况\n",
    "\n",
    "请以如下 JSON 结构输出判断：\n",
    "{{\n",
    "  \"time\": true/false,\n",
    "  \"location\": true/false,\n",
    "  \"incident\": true/false,\n",
    "  \"missing_fields\": [\"time\", \"location\"]  // 若有缺失，请列出\n",
    "}}\n",
    "\n",
    "描述如下：\n",
    "{state['user_input']}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    result = json.loads(response.content)\n",
    "    state[\"missing_fields\"] = result.get(\"missing_fields\", [])\n",
    "    return state\n",
    "\n",
    "# 2. 提示用户补充\n",
    "def ask_for_more(state: State) -> State:\n",
    "    missing = \", \".join(state[\"missing_fields\"])\n",
    "    prompt = f\"\"\"\n",
    "您好，您提供的描述缺少以下信息：{missing}。\n",
    "请您补充这部分内容，例如：\n",
    "- 时间：今天是什么时候发现的？\n",
    "- 地点：具体是在哪条路或哪个路段？\n",
    "- 情况：大概有多严重？是否影响交通？\n",
    "\n",
    "请补充完整描述：\n",
    "    \"\"\"\n",
    "    print(prompt)  # 或发回前端交互界面\n",
    "    new_input = input(\"请输入补充内容：\")  # 模拟人类用户回复\n",
    "    state[\"user_input\"] += \" \" + new_input\n",
    "    return state\n",
    "\n",
    "# 3. 生成 JSON 表单\n",
    "def generate_json(state: State) -> State:\n",
    "    prompt = f\"\"\"\n",
    "你是一位城市治理专家，请从以下描述中提取关键信息，并输出如下 JSON 格式：\n",
    "{{\n",
    "  \"time\": \"...\",\n",
    "  \"location\": \"...\",\n",
    "  \"description\": \"...\",\n",
    "  \"reporter\": \"...\",\n",
    "  \"images\": []\n",
    "}}\n",
    "描述如下：\n",
    "{state['user_input']}\n",
    "    \"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    state[\"json_output\"] = json.loads(response.content)\n",
    "    print(\"✅ 表单生成成功：\", state[\"json_output\"])\n",
    "    return state\n",
    "\n",
    "# ----------- LangGraph 状态图 -----------\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"check_completeness\", check_completeness)\n",
    "workflow.add_node(\"ask_for_more\", ask_for_more)\n",
    "workflow.add_node(\"generate_json\", generate_json)\n",
    "\n",
    "workflow.set_entry_point(\"check_completeness\")\n",
    "\n",
    "# 动态路由判断是否完整，判定条件\n",
    "def is_complete(state: State) -> str:\n",
    "    if not state[\"missing_fields\"]:\n",
    "        return \"generate_json\"\n",
    "    else:\n",
    "        return \"ask_for_more\"\n",
    "\n",
    "workflow.add_conditional_edges(\"check_completeness\", is_complete)\n",
    "workflow.add_edge(\"ask_for_more\", \"check_completeness\")  # 多轮补充\n",
    "workflow.add_edge(\"generate_json\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# ----------- 执行示例 -----------\n",
    "initial_state = {\n",
    "    \"user_input\": \"我在科技园看到路上很多泥，可能是泥头车干的\",\n",
    "    \"missing_fields\": None,\n",
    "    \"json_output\": None,\n",
    "}\n",
    "\n",
    "result = app.invoke(initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4ce1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load environment variables\n",
    "import os\n",
    "# import sys\n",
    "# sys.path.append('../..')\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80390343",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TypedDict, Optional\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI  \u001b[38;5;66;03m# 替换为 DeepSeek-R1 的兼容模型\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/holistic/lib/python3.12/site-packages/langchain/chat_models/__init__.py:29\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chat_models\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# If not in interactive env, raise warning.\u001b[39;00m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive_env():\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Optional\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.chat_models import ChatOpenAI  # 替换为 DeepSeek-R1 的兼容模型\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# 1. 定义状态结构\n",
    "class EventState(TypedDict):\n",
    "    raw_input: str\n",
    "    filled_input: str\n",
    "    json_data: Optional[dict]\n",
    "    missing_fields: list\n",
    "    assigned_entity: Optional[str]\n",
    "    dispatch_status: Optional[str]\n",
    "\n",
    "# 2. 初始化模型（可替换为 DeepSeek-R1）\n",
    "llm = ChatOpenAI(\n",
    "    model=\"r1w8a8\",\n",
    "    temperature=0,\n",
    "    openai_api_key=os.environ[\"W8A8_API_KEY\"],\n",
    "    openai_api_base=\"http://223.2.249.70:7019/v1\",\n",
    ")\n",
    "\n",
    "# 3. 节点定义\n",
    "\n",
    "def receive_report(state: EventState) -> EventState:\n",
    "    state['filled_input'] = state['raw_input']\n",
    "    return state\n",
    "\n",
    "def check_and_complete_info(state: EventState) -> EventState:\n",
    "    prompt = f\"\"\"\n",
    "你是一位城市治理智能助理，现在收到一条描述，请判断是否包含以下信息：时间、地点、事件情况。\n",
    "请以如下格式返回：\n",
    "{{\n",
    "  \"time\": true/false,\n",
    "  \"location\": true/false,\n",
    "  \"incident\": true/false,\n",
    "  \"missing_fields\": [\"time\", \"location\"]\n",
    "}}\n",
    "描述如下：\n",
    "{state['filled_input']}\n",
    "    \"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    result = json.loads(response.content)\n",
    "    state['missing_fields'] = result.get(\"missing_fields\", [])\n",
    "    return state\n",
    "\n",
    "def ask_for_more(state: EventState) -> EventState:\n",
    "    missing = \", \".join(state['missing_fields'])\n",
    "    print(f\"⚠️ 信息缺失：{missing}，请补充如下内容。\")\n",
    "    user_reply = input(\"请输入补充描述：\")\n",
    "    state['filled_input'] += \" \" + user_reply\n",
    "    return state\n",
    "\n",
    "def extract_json(state: EventState) -> EventState:\n",
    "    prompt = f\"\"\"\n",
    "请从下列事件描述中提取如下 JSON 信息：\n",
    "{{\n",
    "  \"time\": \"\",\n",
    "  \"location\": \"\",\n",
    "  \"description\": \"\",\n",
    "  \"reporter\": \"\",\n",
    "  \"images\": []\n",
    "}}\n",
    "描述如下：\n",
    "{state['filled_input']}\n",
    "    \"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    state['json_data'] = json.loads(response.content)\n",
    "    return state\n",
    "\n",
    "def assign_responsibility(state: EventState) -> EventState:\n",
    "    prompt = f\"\"\"\n",
    "你是一位城市治理责任判定专家，请判断事件责任应归属于哪一类：运输企业、工地企业或环卫公司。\n",
    "返回格式：{{\"responsibility\": \"运输企业\", \"reason\": \"...\"}}\n",
    "描述如下：\n",
    "{state['filled_input']}\n",
    "    \"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    result = json.loads(response.content)\n",
    "    state['assigned_entity'] = result['responsibility']\n",
    "    return state\n",
    "\n",
    "def dispatch_task(state: EventState) -> EventState:\n",
    "    now = datetime.datetime.now()\n",
    "    deadline = now + datetime.timedelta(hours=2)\n",
    "    dispatch_record = {\n",
    "        \"event_id\": now.strftime(\"%Y%m%d%H%M%S\"),\n",
    "        \"time\": state['json_data'].get(\"time\", str(now)),\n",
    "        \"location\": state['json_data'].get(\"location\", \"未知\"),\n",
    "        \"description\": state['json_data'].get(\"description\", \"\"),\n",
    "        \"dispatched_to\": state['assigned_entity'],\n",
    "        \"dispatch_deadline\": deadline.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "        \"status\": \"已派遣\"\n",
    "    }\n",
    "    state['dispatch_status'] = json.dumps(dispatch_record, ensure_ascii=False, indent=2)\n",
    "    print(\"✅ 派遣成功，记录如下：\")\n",
    "    print(state['dispatch_status'])\n",
    "    return state\n",
    "\n",
    "# 4. 构建LangGraph\n",
    "workflow = StateGraph(EventState)\n",
    "\n",
    "workflow.add_node(\"receive_report\", receive_report)\n",
    "workflow.add_node(\"check_and_complete_info\", check_and_complete_info)\n",
    "workflow.add_node(\"ask_for_more\", ask_for_more)\n",
    "workflow.add_node(\"extract_json\", extract_json)\n",
    "workflow.add_node(\"assign_responsibility\", assign_responsibility)\n",
    "workflow.add_node(\"dispatch_task\", dispatch_task)\n",
    "\n",
    "workflow.set_entry_point(\"receive_report\")\n",
    "\n",
    "def is_info_complete(state: EventState) -> str:\n",
    "    return \"extract_json\" if not state['missing_fields'] else \"ask_for_more\"\n",
    "\n",
    "workflow.add_conditional_edges(\"check_and_complete_info\", is_info_complete)\n",
    "workflow.add_edge(\"receive_report\", \"check_and_complete_info\")\n",
    "workflow.add_edge(\"ask_for_more\", \"check_and_complete_info\")\n",
    "workflow.add_edge(\"extract_json\", \"assign_responsibility\")\n",
    "workflow.add_edge(\"assign_responsibility\", \"dispatch_task\")\n",
    "workflow.add_edge(\"dispatch_task\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# 5. 示例运行\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = input(\"请输入泥头车遗撒事件描述：\")\n",
    "    initial_state = {\n",
    "        \"raw_input\": user_input,\n",
    "        \"filled_input\": \"\",\n",
    "        \"json_data\": {},\n",
    "        \"missing_fields\": [],\n",
    "        \"assigned_entity\": None,\n",
    "        \"dispatch_status\": None\n",
    "    }\n",
    "    app.invoke(initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e337f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holistic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
