{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f57ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.5.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.95.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting langchain-core>=0.1 (from langgraph)\n",
      "  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.6.0,>=0.5.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.72-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pydantic>=2.7.4 (from langgraph)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp312-cp312-win_amd64.whl.metadata (44 kB)\n",
      "Collecting httpx>=0.25.2 (from langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Downloading orjson-3.10.18-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.5-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.41-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core>=0.1->langgraph)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core>=0.1->langgraph)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core>=0.1->langgraph)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.4->langgraph)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.7.4->langgraph)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.7.4->langgraph)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Using cached charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Using cached certifi-2025.7.9-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.3-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\iwcyo\\miniconda3\\envs\\dev\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading langgraph-0.5.2-py3-none-any.whl (143 kB)\n",
      "Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl (23 kB)\n",
      "Downloading langgraph_sdk-0.1.72-py3-none-any.whl (50 kB)\n",
      "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 6.9 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.68-py3-none-any.whl (441 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 26.9 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl (105 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 59.7 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading openai-1.95.1-py3-none-any.whl (755 kB)\n",
      "   ---------------------------------------- 0.0/755.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 755.6/755.6 kB 32.9 MB/s eta 0:00:00\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp312-cp312-win_amd64.whl (206 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached certifi-2025.7.9-py3-none-any.whl (159 kB)\n",
      "Downloading greenlet-3.2.3-cp312-cp312-win_amd64.whl (297 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading langsmith-0.4.5-py3-none-any.whl (367 kB)\n",
      "Downloading orjson-3.10.18-cp312-cp312-win_amd64.whl (134 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "Downloading ormsgpack-1.10.0-cp312-cp312-win_amd64.whl (121 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Installing collected packages: zstandard, xxhash, urllib3, typing-inspection, tqdm, tenacity, sniffio, PyYAML, pydantic-core, packaging, ormsgpack, orjson, jsonpointer, jiter, idna, h11, greenlet, distro, charset_normalizer, certifi, annotated-types, SQLAlchemy, requests, pydantic, jsonpatch, httpcore, anyio, requests-toolbelt, httpx, openai, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-text-splitters, langgraph-prebuilt, langchain, langgraph\n",
      "\n",
      "   ---- -----------------------------------  4/38 [tqdm]\n",
      "   -------- -------------------------------  8/38 [pydantic-core]\n",
      "  Attempting uninstall: packaging\n",
      "   -------- -------------------------------  8/38 [pydantic-core]\n",
      "    Found existing installation: packaging 25.0\n",
      "   -------- -------------------------------  8/38 [pydantic-core]\n",
      "    Uninstalling packaging-25.0:\n",
      "   -------- -------------------------------  8/38 [pydantic-core]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   -------- -------------------------------  8/38 [pydantic-core]\n",
      "   -------------- ------------------------- 14/38 [idna]\n",
      "   ------------------ --------------------- 18/38 [charset_normalizer]\n",
      "   ---------------------- ----------------- 21/38 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 21/38 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 21/38 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 21/38 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 21/38 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 21/38 [SQLAlchemy]\n",
      "   ------------------------ --------------- 23/38 [pydantic]\n",
      "   ------------------------ --------------- 23/38 [pydantic]\n",
      "   -------------------------- ------------- 25/38 [httpcore]\n",
      "   ---------------------------- ----------- 27/38 [requests-toolbelt]\n",
      "   ------------------------------ --------- 29/38 [openai]\n",
      "   ------------------------------ --------- 29/38 [openai]\n",
      "   ------------------------------ --------- 29/38 [openai]\n",
      "   ------------------------------ --------- 29/38 [openai]\n",
      "   ------------------------------ --------- 29/38 [openai]\n",
      "   ------------------------------ --------- 29/38 [openai]\n",
      "   ------------------------------ --------- 29/38 [openai]\n",
      "   ------------------------------- -------- 30/38 [langsmith]\n",
      "   --------------------------------- ------ 32/38 [langchain-core]\n",
      "   --------------------------------- ------ 32/38 [langchain-core]\n",
      "   --------------------------------- ------ 32/38 [langchain-core]\n",
      "   ------------------------------------- -- 36/38 [langchain]\n",
      "   ------------------------------------- -- 36/38 [langchain]\n",
      "   ------------------------------------- -- 36/38 [langchain]\n",
      "   ------------------------------------- -- 36/38 [langchain]\n",
      "   ------------------------------------- -- 36/38 [langchain]\n",
      "   ------------------------------------- -- 36/38 [langchain]\n",
      "   ------------------------------------- -- 36/38 [langchain]\n",
      "   ------------------------------------- -- 36/38 [langchain]\n",
      "   ------------------------------------- -- 36/38 [langchain]\n",
      "   ------------------------------------- -- 36/38 [langchain]\n",
      "   ------------------------------------- -- 36/38 [langchain]\n",
      "   ------------------------------------- -- 36/38 [langchain]\n",
      "   -------------------------------------- - 37/38 [langgraph]\n",
      "   ---------------------------------------- 38/38 [langgraph]\n",
      "\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.41 annotated-types-0.7.0 anyio-4.9.0 certifi-2025.7.9 charset_normalizer-3.4.2 distro-1.9.0 greenlet-3.2.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jiter-0.10.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.26 langchain-core-0.3.68 langchain-text-splitters-0.3.8 langgraph-0.5.2 langgraph-checkpoint-2.1.0 langgraph-prebuilt-0.5.2 langgraph-sdk-0.1.72 langsmith-0.4.5 openai-1.95.1 orjson-3.10.18 ormsgpack-1.10.0 packaging-24.2 pydantic-2.11.7 pydantic-core-2.33.2 requests-2.32.4 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tqdm-4.67.1 typing-inspection-0.4.1 urllib3-2.5.0 xxhash-3.5.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)'))': /simple/langgraph/\n",
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)'))': /packages/3b/44/6e6c41a3cc00d533dc91cc5f086862b1fccf34aa0ec9605a2cbd116c6ba0/langgraph-0.5.2-py3-none-any.whl.metadata\n"
     ]
    }
   ],
   "source": [
    "%pip install langgraph langchain openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c0a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\iwcyou\\.conda\\envs\\dev\\lib\\site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "# sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=\"anthropic:claude-3-7-sonnet-latest\",\n",
    "    tools=[get_weather],\n",
    "    prompt=\"You are a helpful assistant\"\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a282e948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Okay, the user just said \"Hello\". I should respond in a friendly and welcoming manner. Maybe ask how I can assist them today. Keep it open-ended so they feel comfortable to ask anything. Let me make sure the response is warm and approachable.\n",
      "\n",
      "Hmm, should I use an exclamation mark to sound more enthusiastic? Yeah, \"Hello! How can I assist you today?\" sounds good. It's simple and to the point. I don't want to overwhelm them with too much text. Just let them know I'm here to help. Yep, that works.\n",
      "</think>\n",
      "\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# DeepSeek-r1 model\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ['API_KEY'], base_url=os.environ['BASE_URL'])\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"r1w8a8\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#在工单接收节点添加了信息不足反馈机制，但并不包括复杂逻辑以及RAG\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Optional\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.chat_models import ChatOpenAI  # 可替换为DeepSeek-R1\n",
    "import json\n",
    "\n",
    "# ----------- 状态定义 -----------\n",
    "class State(TypedDict):\n",
    "    user_input: str\n",
    "    missing_fields: Optional[list]\n",
    "    json_output: Optional[dict]\n",
    "\n",
    "# ----------- 初始化模型 -----------\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)  # 替换为 DeepSeek-R1 接口也可\n",
    "\n",
    "# ----------- 节点定义 -----------\n",
    "\n",
    "# 1. 检查输入完整性\n",
    "def check_completeness(state: State) -> State:\n",
    "    prompt = f\"\"\"\n",
    "你是一位城市治理智能助理，现在收到一条来自环卫工人的描述，请你判断该描述是否包含以下三类信息：\n",
    "1. 时间信息\n",
    "2. 地点信息\n",
    "3. 遗洒情况\n",
    "\n",
    "请以如下 JSON 结构输出判断：\n",
    "{{\n",
    "  \"time\": true/false,\n",
    "  \"location\": true/false,\n",
    "  \"incident\": true/false,\n",
    "  \"missing_fields\": [\"time\", \"location\"]  // 若有缺失，请列出\n",
    "}}\n",
    "\n",
    "描述如下：\n",
    "{state['user_input']}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    result = json.loads(response.content)\n",
    "    state[\"missing_fields\"] = result.get(\"missing_fields\", [])\n",
    "    return state\n",
    "\n",
    "# 2. 提示用户补充\n",
    "def ask_for_more(state: State) -> State:\n",
    "    missing = \", \".join(state[\"missing_fields\"])\n",
    "    prompt = f\"\"\"\n",
    "您好，您提供的描述缺少以下信息：{missing}。\n",
    "请您补充这部分内容，例如：\n",
    "- 时间：今天是什么时候发现的？\n",
    "- 地点：具体是在哪条路或哪个路段？\n",
    "- 情况：大概有多严重？是否影响交通？\n",
    "\n",
    "请补充完整描述：\n",
    "    \"\"\"\n",
    "    print(prompt)  # 或发回前端交互界面\n",
    "    new_input = input(\"请输入补充内容：\")  # 模拟人类用户回复\n",
    "    state[\"user_input\"] += \" \" + new_input\n",
    "    return state\n",
    "\n",
    "# 3. 生成 JSON 表单\n",
    "def generate_json(state: State) -> State:\n",
    "    prompt = f\"\"\"\n",
    "你是一位城市治理专家，请从以下描述中提取关键信息，并输出如下 JSON 格式：\n",
    "{{\n",
    "  \"time\": \"...\",\n",
    "  \"location\": \"...\",\n",
    "  \"description\": \"...\",\n",
    "  \"reporter\": \"...\",\n",
    "  \"images\": []\n",
    "}}\n",
    "描述如下：\n",
    "{state['user_input']}\n",
    "    \"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    state[\"json_output\"] = json.loads(response.content)\n",
    "    print(\"✅ 表单生成成功：\", state[\"json_output\"])\n",
    "    return state\n",
    "\n",
    "# ----------- LangGraph 状态图 -----------\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"check_completeness\", check_completeness)\n",
    "workflow.add_node(\"ask_for_more\", ask_for_more)\n",
    "workflow.add_node(\"generate_json\", generate_json)\n",
    "\n",
    "workflow.set_entry_point(\"check_completeness\")\n",
    "\n",
    "# 动态路由判断是否完整，判定条件\n",
    "def is_complete(state: State) -> str:\n",
    "    if not state[\"missing_fields\"]:\n",
    "        return \"generate_json\"\n",
    "    else:\n",
    "        return \"ask_for_more\"\n",
    "\n",
    "workflow.add_conditional_edges(\"check_completeness\", is_complete)\n",
    "workflow.add_edge(\"ask_for_more\", \"check_completeness\")  # 多轮补充\n",
    "workflow.add_edge(\"generate_json\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# ----------- 执行示例 -----------\n",
    "initial_state = {\n",
    "    \"user_input\": \"我在科技园看到路上很多泥，可能是泥头车干的\",\n",
    "    \"missing_fields\": None,\n",
    "    \"json_output\": None,\n",
    "}\n",
    "\n",
    "result = app.invoke(initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80390343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Optional\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.chat_models import ChatOpenAI  # 替换为 DeepSeek-R1 的兼容模型\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# 1. 定义状态结构\n",
    "class EventState(TypedDict):\n",
    "    raw_input: str\n",
    "    filled_input: str\n",
    "    json_data: Optional[dict]\n",
    "    missing_fields: list\n",
    "    assigned_entity: Optional[str]\n",
    "    dispatch_status: Optional[str]\n",
    "\n",
    "# 2. 初始化模型（可替换为 DeepSeek-R1）\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "# 3. 节点定义\n",
    "\n",
    "def receive_report(state: EventState) -> EventState:\n",
    "    state['filled_input'] = state['raw_input']\n",
    "    return state\n",
    "\n",
    "def check_and_complete_info(state: EventState) -> EventState:\n",
    "    prompt = f\"\"\"\n",
    "你是一位城市治理智能助理，现在收到一条描述，请判断是否包含以下信息：时间、地点、事件情况。\n",
    "请以如下格式返回：\n",
    "{{\n",
    "  \"time\": true/false,\n",
    "  \"location\": true/false,\n",
    "  \"incident\": true/false,\n",
    "  \"missing_fields\": [\"time\", \"location\"]\n",
    "}}\n",
    "描述如下：\n",
    "{state['filled_input']}\n",
    "    \"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    result = json.loads(response.content)\n",
    "    state['missing_fields'] = result.get(\"missing_fields\", [])\n",
    "    return state\n",
    "\n",
    "def ask_for_more(state: EventState) -> EventState:\n",
    "    missing = \", \".join(state['missing_fields'])\n",
    "    print(f\"⚠️ 信息缺失：{missing}，请补充如下内容。\")\n",
    "    user_reply = input(\"请输入补充描述：\")\n",
    "    state['filled_input'] += \" \" + user_reply\n",
    "    return state\n",
    "\n",
    "def extract_json(state: EventState) -> EventState:\n",
    "    prompt = f\"\"\"\n",
    "请从下列事件描述中提取如下 JSON 信息：\n",
    "{{\n",
    "  \"time\": \"\",\n",
    "  \"location\": \"\",\n",
    "  \"description\": \"\",\n",
    "  \"reporter\": \"\",\n",
    "  \"images\": []\n",
    "}}\n",
    "描述如下：\n",
    "{state['filled_input']}\n",
    "    \"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    state['json_data'] = json.loads(response.content)\n",
    "    return state\n",
    "\n",
    "def assign_responsibility(state: EventState) -> EventState:\n",
    "    prompt = f\"\"\"\n",
    "你是一位城市治理责任判定专家，请判断事件责任应归属于哪一类：运输企业、工地企业或环卫公司。\n",
    "返回格式：{{\"responsibility\": \"运输企业\", \"reason\": \"...\"}}\n",
    "描述如下：\n",
    "{state['filled_input']}\n",
    "    \"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    result = json.loads(response.content)\n",
    "    state['assigned_entity'] = result['responsibility']\n",
    "    return state\n",
    "\n",
    "def dispatch_task(state: EventState) -> EventState:\n",
    "    now = datetime.datetime.now()\n",
    "    deadline = now + datetime.timedelta(hours=2)\n",
    "    dispatch_record = {\n",
    "        \"event_id\": now.strftime(\"%Y%m%d%H%M%S\"),\n",
    "        \"time\": state['json_data'].get(\"time\", str(now)),\n",
    "        \"location\": state['json_data'].get(\"location\", \"未知\"),\n",
    "        \"description\": state['json_data'].get(\"description\", \"\"),\n",
    "        \"dispatched_to\": state['assigned_entity'],\n",
    "        \"dispatch_deadline\": deadline.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "        \"status\": \"已派遣\"\n",
    "    }\n",
    "    state['dispatch_status'] = json.dumps(dispatch_record, ensure_ascii=False, indent=2)\n",
    "    print(\"✅ 派遣成功，记录如下：\")\n",
    "    print(state['dispatch_status'])\n",
    "    return state\n",
    "\n",
    "# 4. 构建LangGraph\n",
    "workflow = StateGraph(EventState)\n",
    "\n",
    "workflow.add_node(\"receive_report\", receive_report)\n",
    "workflow.add_node(\"check_and_complete_info\", check_and_complete_info)\n",
    "workflow.add_node(\"ask_for_more\", ask_for_more)\n",
    "workflow.add_node(\"extract_json\", extract_json)\n",
    "workflow.add_node(\"assign_responsibility\", assign_responsibility)\n",
    "workflow.add_node(\"dispatch_task\", dispatch_task)\n",
    "\n",
    "workflow.set_entry_point(\"receive_report\")\n",
    "\n",
    "def is_info_complete(state: EventState) -> str:\n",
    "    return \"extract_json\" if not state['missing_fields'] else \"ask_for_more\"\n",
    "\n",
    "workflow.add_conditional_edges(\"check_and_complete_info\", is_info_complete)\n",
    "workflow.add_edge(\"receive_report\", \"check_and_complete_info\")\n",
    "workflow.add_edge(\"ask_for_more\", \"check_and_complete_info\")\n",
    "workflow.add_edge(\"extract_json\", \"assign_responsibility\")\n",
    "workflow.add_edge(\"assign_responsibility\", \"dispatch_task\")\n",
    "workflow.add_edge(\"dispatch_task\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# 5. 示例运行\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = input(\"请输入泥头车遗撒事件描述：\")\n",
    "    initial_state = {\n",
    "        \"raw_input\": user_input,\n",
    "        \"filled_input\": \"\",\n",
    "        \"json_data\": {},\n",
    "        \"missing_fields\": [],\n",
    "        \"assigned_entity\": None,\n",
    "        \"dispatch_status\": None\n",
    "    }\n",
    "    app.invoke(initial_state)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
